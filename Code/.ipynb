{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# 設置 logging 配置\n",
    "logging.basicConfig(\n",
    "    filename='training_log.log',  # Log 文件名稱\n",
    "    filemode='a',                 # 'a' 表示追加模式，'w' 表示覆蓋模式\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO             # 設置日誌級別\n",
    ")\n",
    "\n",
    "# 開始記錄\n",
    "logging.info(\"Logging initialized. Starting the training process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.5.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.12.4)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (6.0.2)\n",
      "Requirement already satisfied: shap in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from shap) (4.67.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from shap) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\林滋隆\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba->shap) (0.43.0)\n"
     ]
    }
   ],
   "source": [
    "# 安裝所需庫 (僅在初次運行時執行)\n",
    "!pip install pandas matplotlib seaborn scikit-learn imbalanced-learn pyyaml shap\n",
    "\n",
    "# 導入主要模組\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "\n",
    "# 加載配置文件\n",
    "with open(\"config/config.yaml\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support輔助函數-\n",
    "1.資料處理 # Data Utilities from data_utils.py\n",
    "2.評估指標 # Metrics Utilities from metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Utilities from data_utils.py\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"從 CSV 文件加載數據\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def save_data(df, file_path):\n",
    "    \"\"\"將數據保存為 CSV 文件\"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Utilities from metrics.py\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "def calculate_f1(y_true, y_pred):\n",
    "    \"\"\"計算 Macro F1-Score\"\"\"\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def calculate_auc(y_true, y_proba):\n",
    "    \"\"\"計算 AUROC 分數\"\"\"\n",
    "    return roc_auc_score(y_true, y_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (44939, 83)\n",
      "Test data shape: (19260, 83)\n",
      "Target shape: (44939, 1)\n"
     ]
    }
   ],
   "source": [
    "# 加載數據\n",
    "train_X_path = config['data_paths']['train_X']\n",
    "train_y_path = config['data_paths']['train_y']\n",
    "test_X_path = config['data_paths']['test_X']\n",
    "\n",
    "# 使用 data_utils 中的 load_data 函數加載數據\n",
    "train_data = load_data(config['data_paths']['train_X'])\n",
    "train_target = load_data(config['data_paths']['train_y'])\n",
    "test_data = load_data(config['data_paths']['test_X'])\n",
    "\n",
    "# 檢查數據形狀\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Target shape:\", train_target.shape)\n",
    "\n",
    "# logging\n",
    "try:\n",
    "    train_data = load_data(config['data_paths']['train_X'])\n",
    "    train_target = load_data(config['data_paths']['train_y'])\n",
    "    test_data = load_data(config['data_paths']['test_X'])\n",
    "    logging.info(f\"Data loaded successfully. Train shape: {train_data.shape}, Test shape: {test_data.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading data: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      " encounter_id                     int64\n",
      "patient_id                       int64\n",
      "hospital_id                      int64\n",
      "age                            float64\n",
      "bmi                            float64\n",
      "                                ...   \n",
      "leukemia                       float64\n",
      "lymphoma                       float64\n",
      "solid_tumor_with_metastasis    float64\n",
      "apache_3j_bodysystem            object\n",
      "apache_2_bodysystem             object\n",
      "Length: 83, dtype: object\n",
      "First few rows:\n",
      "    encounter_id  patient_id  hospital_id   age        bmi  elective_surgery  \\\n",
      "0        126956      125763           26  75.0  23.147277                 0   \n",
      "1         18184       25399           54  42.0  35.071807                 1   \n",
      "2         51597        7974           81  39.0        NaN                 0   \n",
      "3         40078       79625          161  62.0  42.070672                 0   \n",
      "4        130673       88261           29  82.0        NaN                 0   \n",
      "\n",
      "          ethnicity gender  height           icu_admit_source  ...  aids  \\\n",
      "0             Asian      M   163.0       Accident & Emergency  ...   0.0   \n",
      "1         Caucasian      F   157.5  Operating Room / Recovery  ...   0.0   \n",
      "2  African American      M   182.9       Accident & Emergency  ...   0.0   \n",
      "3          Hispanic      F   157.0       Accident & Emergency  ...   0.0   \n",
      "4         Caucasian      F     NaN       Accident & Emergency  ...   0.0   \n",
      "\n",
      "  cirrhosis diabetes_mellitus  hepatic_failure  immunosuppression  leukemia  \\\n",
      "0       0.0               0.0              0.0                0.0       0.0   \n",
      "1       0.0               0.0              0.0                0.0       0.0   \n",
      "2       0.0               0.0              0.0                0.0       0.0   \n",
      "3       1.0               0.0              1.0                0.0       0.0   \n",
      "4       0.0               0.0              0.0                0.0       0.0   \n",
      "\n",
      "   lymphoma  solid_tumor_with_metastasis  apache_3j_bodysystem  \\\n",
      "0       0.0                          0.0                Trauma   \n",
      "1       0.0                          0.0        Cardiovascular   \n",
      "2       0.0                          0.0          Neurological   \n",
      "3       0.0                          0.0      Gastrointestinal   \n",
      "4       0.0                          0.0                Trauma   \n",
      "\n",
      "   apache_2_bodysystem  \n",
      "0               Trauma  \n",
      "1  Undefined diagnoses  \n",
      "2           Neurologic  \n",
      "3     Gastrointestinal  \n",
      "4               Trauma  \n",
      "\n",
      "[5 rows x 83 columns]\n",
      "Missing values:\n",
      " encounter_id                      0\n",
      "patient_id                        0\n",
      "hospital_id                       0\n",
      "age                            2065\n",
      "bmi                            1651\n",
      "                               ... \n",
      "leukemia                        346\n",
      "lymphoma                        346\n",
      "solid_tumor_with_metastasis     346\n",
      "apache_3j_bodysystem            807\n",
      "apache_2_bodysystem             807\n",
      "Length: 83, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 基本數據檢查\n",
    "print(\"Data types:\\n\", train_data.dtypes)\n",
    "print(\"First few rows:\\n\", train_data.head())\n",
    "print(\"Missing values:\\n\", train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data analysis（EDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description of training data:\n",
      "Statistical Summary:\n",
      "\n",
      "        encounter_id     patient_id   hospital_id           age           bmi  \\\n",
      "count   44939.000000   44939.000000  44939.000000  42874.000000  43288.000000   \n",
      "mean    65642.668751   65491.091346    105.732460     62.318701     29.195878   \n",
      "std     37736.732171   37696.448956     62.901289     16.804263      8.263748   \n",
      "min         1.000000       1.000000      2.000000     16.000000     14.844926   \n",
      "25%     33059.000000   32732.000000     47.000000     52.000000     23.638493   \n",
      "50%     65732.000000   65467.000000    109.000000     65.000000     27.680158   \n",
      "75%     98239.500000   98089.500000    161.000000     75.000000     32.962064   \n",
      "max    131049.000000  131049.000000    204.000000     89.000000     67.814990   \n",
      "\n",
      "       elective_surgery        height        icu_id  pre_icu_los_days  \\\n",
      "count      44939.000000  44308.000000  44939.000000      44939.000000   \n",
      "mean           0.182314    169.565517    509.502659          0.836469   \n",
      "std            0.386107     10.788113    228.631369          2.565688   \n",
      "min            0.000000    137.200000     82.000000        -13.775000   \n",
      "25%            0.000000    162.500000    369.000000          0.034722   \n",
      "50%            0.000000    170.000000    504.000000          0.138194   \n",
      "75%            0.000000    177.800000    683.000000          0.410417   \n",
      "max            1.000000    195.590000    927.000000        159.090972   \n",
      "\n",
      "             weight  ...  apache_4a_hospital_death_prob  \\\n",
      "count  43632.000000  ...                   41048.000000   \n",
      "mean      84.002241  ...                       0.085992   \n",
      "std       25.016278  ...                       0.248608   \n",
      "min       38.600000  ...                      -1.000000   \n",
      "25%       66.700000  ...                       0.020000   \n",
      "50%       80.300000  ...                       0.050000   \n",
      "75%       97.100000  ...                       0.130000   \n",
      "max      186.000000  ...                       0.980000   \n",
      "\n",
      "       apache_4a_icu_death_prob          aids     cirrhosis  \\\n",
      "count              41048.000000  44593.000000  44593.000000   \n",
      "mean                   0.043790      0.000718      0.015541   \n",
      "std                    0.217667      0.026779      0.123691   \n",
      "min                   -1.000000      0.000000      0.000000   \n",
      "25%                    0.010000      0.000000      0.000000   \n",
      "50%                    0.020000      0.000000      0.000000   \n",
      "75%                    0.060000      0.000000      0.000000   \n",
      "max                    0.970000      1.000000      1.000000   \n",
      "\n",
      "       diabetes_mellitus  hepatic_failure  immunosuppression      leukemia  \\\n",
      "count       44593.000000     44593.000000       44593.000000  44593.000000   \n",
      "mean            0.223959         0.013208           0.025206      0.007064   \n",
      "std             0.416900         0.114167           0.156751      0.083751   \n",
      "min             0.000000         0.000000           0.000000      0.000000   \n",
      "25%             0.000000         0.000000           0.000000      0.000000   \n",
      "50%             0.000000         0.000000           0.000000      0.000000   \n",
      "75%             0.000000         0.000000           0.000000      0.000000   \n",
      "max             1.000000         1.000000           1.000000      1.000000   \n",
      "\n",
      "           lymphoma  solid_tumor_with_metastasis  \n",
      "count  44593.000000                 44593.000000  \n",
      "mean       0.004193                     0.020676  \n",
      "std        0.064622                     0.142298  \n",
      "min        0.000000                     0.000000  \n",
      "25%        0.000000                     0.000000  \n",
      "50%        0.000000                     0.000000  \n",
      "75%        0.000000                     0.000000  \n",
      "max        1.000000                     1.000000  \n",
      "\n",
      "[8 rows x 76 columns]\n",
      "\n",
      "Missing Values Analysis:\n",
      "Missing Values:\n",
      " age                            2065\n",
      "bmi                            1651\n",
      "ethnicity                       700\n",
      "gender                           13\n",
      "height                          631\n",
      "                               ... \n",
      "leukemia                        346\n",
      "lymphoma                        346\n",
      "solid_tumor_with_metastasis     346\n",
      "apache_3j_bodysystem            807\n",
      "apache_2_bodysystem             807\n",
      "Length: 74, dtype: int64\n",
      "\n",
      "Missing Percentage:\n",
      " age                            4.595118\n",
      "bmi                            3.673869\n",
      "ethnicity                      1.557667\n",
      "gender                         0.028928\n",
      "height                         1.404126\n",
      "                                 ...   \n",
      "leukemia                       0.769933\n",
      "lymphoma                       0.769933\n",
      "solid_tumor_with_metastasis    0.769933\n",
      "apache_3j_bodysystem           1.795768\n",
      "apache_2_bodysystem            1.795768\n",
      "Length: 74, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 基本統計\n",
    "def describe_data(data):\n",
    "    print(\"Statistical Summary:\\n\")\n",
    "    return data.describe()\n",
    "\n",
    "# 缺失值檢查\n",
    "def check_missing_values(data):\n",
    "    missing_data = data.isnull().sum()\n",
    "    missing_percentage = (missing_data / len(data)) * 100\n",
    "    return missing_data[missing_data > 0], missing_percentage[missing_percentage > 0]\n",
    "\n",
    "# 執行數據分析\n",
    "print(\"Description of training data:\")\n",
    "print(describe_data(train_data))  # 統一打印描述性統計\n",
    "print(\"\\nMissing Values Analysis:\")\n",
    "missing_data, missing_percentage = check_missing_values(train_data)\n",
    "print(\"Missing Values:\\n\", missing_data)\n",
    "print(\"\\nMissing Percentage:\\n\", missing_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數值特徵的成對散佈圖（Pair Plot）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'numerical_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m     sns\u001b[38;5;241m.\u001b[39mpairplot(data[numerical_columns]\u001b[38;5;241m.\u001b[39mdropna())\n\u001b[0;32m      3\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m----> 5\u001b[0m plot_pairplot(train_data, \u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnumerical_columns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'numerical_columns'"
     ]
    }
   ],
   "source": [
    "def plot_pairplot(data, numerical_columns):\n",
    "    sns.pairplot(data[numerical_columns].dropna())\n",
    "    plt.show()\n",
    "\n",
    "plot_pairplot(train_data, config['numerical_columns'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數值特徵的箱線圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boxplots(data, numerical_columns):\n",
    "    for column in numerical_columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.boxplot(x=data[column].dropna())\n",
    "        plt.title(f'Boxplot of {column}')\n",
    "        plt.show()\n",
    "\n",
    "plot_boxplots(train_data, config['numerical_columns'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數值特徵的直方圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_numeric_distributions(data, numerical_columns):\n",
    "    for column in numerical_columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.histplot(data[column].dropna(), kde=True)\n",
    "        plt.title(f'Distribution of {column}')\n",
    "        plt.show()\n",
    "\n",
    "# 假設數值特徵名稱為 'numerical_columns'\n",
    "plot_numeric_distributions(train_data, config['numerical_columns'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目標變數的分佈圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_target_distribution(data, target_column):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(x=data[target_column])\n",
    "    plt.title(f'Distribution of target variable: {target_column}')\n",
    "    plt.show()\n",
    "\n",
    "# 假設目標變數名稱為 'target_column'\n",
    "plot_target_distribution(train_data, 'target_column')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類別特徵的頻率圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_counts(data, categorical_columns):\n",
    "    for column in categorical_columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.countplot(x=data[column])\n",
    "        plt.title(f'Count of each category in {column}')\n",
    "        plt.show()\n",
    "\n",
    "# 假設類別特徵名稱為 'categorical_columns'\n",
    "categorical_columns = ['column1', 'column2']  # 替換為你的類別特徵名稱\n",
    "plot_categorical_counts(train_data, categorical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## missing value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總共有:44939位病人\n",
      "Missing Values:\n",
      " age                            2065\n",
      "bmi                            1651\n",
      "ethnicity                       700\n",
      "gender                           13\n",
      "height                          631\n",
      "                               ... \n",
      "leukemia                        346\n",
      "lymphoma                        346\n",
      "solid_tumor_with_metastasis     346\n",
      "apache_3j_bodysystem            807\n",
      "apache_2_bodysystem             807\n",
      "Length: 74, dtype: int64\n",
      "Missing Percentage:\n",
      " age                            4.595118\n",
      "bmi                            3.673869\n",
      "ethnicity                      1.557667\n",
      "gender                         0.028928\n",
      "height                         1.404126\n",
      "                                 ...   \n",
      "leukemia                       0.769933\n",
      "lymphoma                       0.769933\n",
      "solid_tumor_with_metastasis    0.769933\n",
      "apache_3j_bodysystem           1.795768\n",
      "apache_2_bodysystem            1.795768\n",
      "Length: 74, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# 開啟一個 .txt 檔案並寫入缺失值數量和缺失百分比\\nwith open(\\'missing_data.txt\\', \\'w\\') as f:\\n    f.write(\"Missing Values:\\n\")\\n    f.write(missing_data.to_string())  # 寫入缺失值數量\\n    f.write(\"\\n\\nMissing Percentage:\\n\")\\n    f.write(missing_percentage.to_string())  # 寫入缺失百分比\\n\\nmissing_summary = pd.DataFrame({\\n    \\'Missing Values\\': missing_data,\\n    \\'Missing Percentage\\': missing_percentage\\n})\\nmissing_summary.to_csv(\\'missing_data.csv\\', index=True)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缺失值檢查\n",
    "missing_data = train_data.isnull().sum()\n",
    "missing_percentage = (missing_data / len(train_data)) * 100\n",
    "print(f\"總共有:{len(train_data)}位病人\")\n",
    "print(\"Missing Values:\\n\", missing_data[missing_data > 0])\n",
    "print(\"Missing Percentage:\\n\", missing_percentage[missing_percentage > 0])\n",
    "\n",
    "'''# 開啟一個 .txt 檔案並寫入缺失值數量和缺失百分比\n",
    "with open('missing_data.txt', 'w') as f:\n",
    "    f.write(\"Missing Values:\\n\")\n",
    "    f.write(missing_data.to_string())  # 寫入缺失值數量\n",
    "    f.write(\"\\n\\nMissing Percentage:\\n\")\n",
    "    f.write(missing_percentage.to_string())  # 寫入缺失百分比\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Values': missing_data,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "missing_summary.to_csv('missing_data.csv', index=True)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 刪除 threshold under 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除缺失值\n",
    "def drop_missing_values(data, threshold=0.5):\n",
    "    return data.loc[:, data.isnull().mean() < threshold]\n",
    "\n",
    "# 執行清理\n",
    "train_data = drop_missing_values(train_data, threshold=config.get('missing_value_threshold', 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 填補(KNN插補)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# 檢查是否有缺失值的列\n",
    "missing_cols = train_data.columns[train_data.isnull().any()]\n",
    "if len(missing_cols) > 0:\n",
    "    # 初始化 KNNImputer 並使用配置中的 n_neighbors\n",
    "    knn_imputer = KNNImputer(n_neighbors=config['model_params']['n_neighbors'])\n",
    "    \n",
    "    # 進行 KNN 插補\n",
    "    train_data[missing_cols] = knn_imputer.fit_transform(train_data[missing_cols])\n",
    "    print(f\"KNN imputation completed for columns: {list(missing_cols)} with n_neighbors={config['model_params']['n_neighbors']}\")\n",
    "else:\n",
    "    print(\"No missing values found for KNN imputation.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 類別特徵編碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# 根據 config.yaml 中的 categorical_encoding 配置選擇編碼方法\n",
    "if config['model_params']['categorical_encoding'] == 'onehot':\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_df = pd.DataFrame(encoder.fit_transform(train_data[['categorical_column']]),\n",
    "                              columns=encoder.get_feature_names_out(['categorical_column']))\n",
    "    train_data = train_data.drop('categorical_column', axis=1).join(encoded_df)\n",
    "elif config['model_params']['categorical_encoding'] == 'label':\n",
    "    encoder = LabelEncoder()\n",
    "    train_data['categorical_column'] = encoder.fit_transform(train_data['categorical_column'])\n",
    "else:\n",
    "    raise ValueError(\"Unsupported categorical encoding type in config.yaml\")\n",
    "\n",
    "print(f\"Categorical encoding applied using {config['model_params']['categorical_encoding']} encoding.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 數值特徵標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 根據 config.yaml 中的 scaler 配置選擇縮放方法\n",
    "if config['model_params']['scaler'] == 'standard':\n",
    "    scaler = StandardScaler()\n",
    "elif config['model_params']['scaler'] == 'minmax':\n",
    "    scaler = MinMaxScaler()\n",
    "else:\n",
    "    raise ValueError(\"Unsupported scaler type in config.yaml\")\n",
    "\n",
    "# 應用選擇的縮放方法\n",
    "train_data[config['numerical_columns']] = scaler.fit_transform(train_data[config['numerical_columns']])\n",
    "print(f\"Data scaled using {config['model_params']['scaler']} scaler.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance 處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平衡數據\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 使用配置中的 smote_strategy 和 random_state 參數\n",
    "smote = SMOTE(sampling_strategy=config['model_params']['smote_strategy'], random_state=config['model_params']['random_state'])\n",
    "train_data_res, train_target_res = smote.fit_resample(train_data, train_target)\n",
    "print(f\"Data imbalance handled with SMOTE strategy: {config['model_params']['smote_strategy']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(data, column):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(data[column], kde=True)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplot(data, column):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=data[column])\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    plt.show()\n",
    "\n",
    "for col in config['numerical_columns']:\n",
    "    plot_distribution(train_data, col)\n",
    "    plot_boxplot(train_data, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相關性矩陣分析(Correlation Matrix Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 繪製相關矩陣的函數\n",
    "def plot_correlation_matrix(data):\n",
    "    # 選擇數值類型的欄位\n",
    "    numeric_data = data.select_dtypes(include=['float64', 'int64'])\n",
    "    \n",
    "    # 繪製相關矩陣\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# 在數據轉換後執行相關性矩陣分析\n",
    "plot_correlation_matrix(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering 特徵工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# PCA 降維的綜合處理函數\n",
    "def apply_pca(data, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    principal_components = pca.fit_transform(data)\n",
    "    pca_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "    return pd.concat([data, pca_df], axis=1)\n",
    "\n",
    "# 使用配置中的 pca_components 參數執行 PCA\n",
    "train_data = apply_pca(train_data, n_components=config['model_params']['pca_components'])\n",
    "print(f\"PCA applied with {config['model_params']['pca_components']} components.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 模型初始化(隨機森林模型)\n",
    "model = RandomForestClassifier(random_state=config['model_params']['random_state'])\n",
    "\n",
    "# 訓練模型\n",
    "model.fit(train_data_res, train_target_res)\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "#訓練模型的logging\n",
    "try:\n",
    "    model.fit(train_data_res, train_target_res)\n",
    "    logging.info(\"Model training completed successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during model training: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross-valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉驗證\n",
    "from sklearn.model_selection import cross_val_score\n",
    "f1_scores = cross_val_score(model, train_data_res, train_target_res, cv=5, scoring='f1_macro')\n",
    "print(\"Cross-validated Macro F1 Score:\", f1_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵重要性分析\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(train_data_res)\n",
    "\n",
    "# 顯示前20個重要特徵\n",
    "shap.summary_plot(shap_values[1], train_data_res, plot_type=\"bar\", max_display=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "test_predictions = model.predict(test_data)\n",
    "\n",
    "# 假設有測試集標籤，進行 AUROC 和 F1 計算\n",
    "# test_true_labels = pd.read_csv(\"path_to_true_labels.csv\")\n",
    "# f1 = f1_score(test_true_labels, test_predictions, average='macro')\n",
    "# auroc = roc_auc_score(test_true_labels, test_predictions)\n",
    "# print(\"Test F1 Score:\", f1)\n",
    "# print(\"Test AUROC:\", auroc)\n",
    "# 假設 test_predictions 是模型在測試集上的預測\n",
    "# 假設 test_proba 是模型預測的概率 (e.g., test_proba = model.predict_proba(test_data))\n",
    "\n",
    "# 示例：計算 F1-Score 和 AUROC\n",
    "f1 = calculate_f1(train_target, test_predictions)\n",
    "auroc = calculate_auc(train_target, test_proba)\n",
    "print(\"Test F1 Score:\", f1)\n",
    "print(\"Test AUROC:\", auroc)\n",
    "\n",
    "\n",
    "# evaluation的logging\n",
    "try:\n",
    "    f1 = calculate_f1(train_target, test_predictions)\n",
    "    auroc = calculate_auc(train_target, test_proba)\n",
    "    logging.info(f\"Evaluation results - F1 Score: {f1}, AUROC: {auroc}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during model evaluation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaggle gogo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 提交文件生成函數\n",
    "def create_submission_file(model, test_data, config):\n",
    "    # 使用模型進行預測\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    # 創建提交 DataFrame，將索引作為 ID 和預測結果 'has_died' 放入\n",
    "    submission = pd.DataFrame({'Id': test_data.index, 'has_died': predictions})\n",
    "    \n",
    "    # 使用配置中的 submission_file 路徑保存文件\n",
    "    submission.to_csv(config['data_paths']['submission_file'], index=False)\n",
    "    print(f\"Submission file saved to {config['data_paths']['submission_file']}\")\n",
    "\n",
    "# 調用函數生成提交文件\n",
    "create_submission_file(model, test_data, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def monitor_model(new_data, true_labels):\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(new_data)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    latency = end_time - start_time\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Prediction Latency: {latency} seconds\")\n",
    "    \n",
    "    return accuracy, f1, latency\n",
    "\n",
    "# 假設 new_test_data 和 new_test_labels 為新數據\n",
    "# monitor_model(new_test_data, new_test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化和配置加載的 Logging\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"config/config.yaml\", \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    logging.info(\"Configuration loaded successfully.\")\n",
    "    logging.info(f\"Configurations: {config}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error loading configuration: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "缺失值處理的 Logging\n",
    "try:\n",
    "    train_data = drop_missing_values(train_data, threshold=0.5)\n",
    "    logging.info(\"Missing values handled successfully. Remaining columns: {train_data.columns}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error handling missing values: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "特徵轉換和標準化的 Logging\n",
    "try:\n",
    "    train_data = encode_categorical(train_data, 'categorical_column')\n",
    "    train_data = standardize_data(train_data, config['numerical_columns'])\n",
    "    logging.info(\"Data transformation and standardization completed.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during data transformation: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "處理數據不平衡的 Logging\n",
    "try:\n",
    "    smote = SMOTE(random_state=config['model_params']['random_state'])\n",
    "    train_data_res, train_target_res = smote.fit_resample(train_data, train_target)\n",
    "    logging.info(\"Data imbalance handled successfully. Resampled data shape: {}\".format(train_data_res.shape))\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during data imbalance handling: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "特徵工程的 Logging\n",
    "try:\n",
    "    train_data = apply_pca(train_data, n_components=2)\n",
    "    logging.info(\"PCA applied successfully. Data shape after PCA: {}\".format(train_data.shape))\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during PCA transformation: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "生成 Kaggle 提交文件的 Logging\n",
    "try:\n",
    "    save_data(submission, \"testing_result.csv\")\n",
    "    logging.info(\"Kaggle submission file created successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error creating Kaggle submission file: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "模型監控的 Logging\n",
    "try:\n",
    "    accuracy, f1, latency = monitor_model(new_test_data, new_test_labels)\n",
    "    logging.info(f\"Monitoring results - Accuracy: {accuracy}, F1 Score: {f1}, Latency: {latency} seconds\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during model monitoring: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
